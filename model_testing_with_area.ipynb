{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0936df-1a01-4b96-97c2-bb5075185bdf",
   "metadata": {
    "id": "5d0936df-1a01-4b96-97c2-bb5075185bdf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 üöÄ 6c32967 torch 1.8.0+cu111 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4037MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "data = 'cut.mp4'\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å\n",
    "model = torch.hub.load(os.path.abspath(\"\") + '/', 'custom', path=os.path.abspath(\"\")+'/runs/train/exp20/weights/best.pt', source='local')\n",
    "model.conf = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedd8bea-2778-45fe-9d52-06519d81809e",
   "metadata": {
    "id": "dedd8bea-2778-45fe-9d52-06519d81809e"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "import pandas\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "def get_avg(r):\n",
    "    result = 0\n",
    "    for i in range(len(r)):\n",
    "        result = result + (r[i][2] - r[i][0])\n",
    "    return result / max(0, len(r))\n",
    "\n",
    "def get_wind_coeff():\n",
    "    return 1\n",
    "\n",
    "def get_fire_radius(distance, screen_width, fire_width):\n",
    "    meta_camera_matrix = 8.46\n",
    "    meta_camera_focal = 120\n",
    "    popravka = 25\n",
    "    fire_meter_width = popravka * 2 * distance * math.tan((fire_width / screen_width) * 2 * math.atan(meta_camera_matrix / (2 * meta_camera_focal)))\n",
    "    return fire_meter_width / 2\n",
    "    # return get_wind_coeff() * (fire_meter_width ** 2) * math.pi / 10000\n",
    "\n",
    "def get_fire_area(distance, screen_width, fire_width):\n",
    "    return get_wind_coeff() * (get_fire_radius(distance, screen_width, fire_width) ** 2) * math.pi / 10000 / 2\n",
    "def compute_point_perspective_transformation(matrix,list_downoids):\n",
    "    list_points_to_detect = np.float32(list_downoids).reshape(-1, 1, 2)\n",
    "    transformed_points = cv2.perspectiveTransform(list_points_to_detect, matrix)\n",
    "    transformed_points_list = []\n",
    "    for i in range(0,transformed_points.shape[0]):\n",
    "        transformed_points_list.append([transformed_points[i][0][0],transformed_points[i][0][1]])\n",
    "    return transformed_points_list\n",
    "\n",
    "def order_points(rect):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "    warped = cv2.warpPerspective(warped, M, (maxWidth, maxHeight))\n",
    "    \n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dc0c14f-6e6c-44e9-b9b2-879a9874ca14",
   "metadata": {
    "id": "8dc0c14f-6e6c-44e9-b9b2-879a9874ca14"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(data)\n",
    "frame_count = 0\n",
    "array_groundpoints = []\n",
    "fire_areas = []\n",
    "dists = []\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc= cv2.VideoWriter_fourcc(*'XVID')\n",
    "out= cv2.VideoWriter('outcut.avi',fourcc, 25.0, (1280, 720)) \n",
    "\n",
    "while cap.isOpened():\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "  \n",
    "    # —á–∏—Ç–∞–µ–º –∫–∞–¥—Ä –∏–∑ –≤–∏–¥–µ–æ\n",
    "    ret, im = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        frame_count += 1\n",
    "        result = Image.fromarray(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # –æ—Ç–¥–∞–µ–º –∫–∞–¥—Ä –≤ –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏\n",
    "        results = model(result)\n",
    "\n",
    "        # –≤—ã–≤–æ–¥–∏–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏\n",
    "        # —Ç–∞–∫–∂–µ —Ä–∏—Å—É–µ–º bounding box –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ç–æ—á–µ–∫\n",
    "        if not results.pandas().xyxy[0].empty:\n",
    "            isAlert = False\n",
    "            #print(results.pandas().xyxy[0])\n",
    "            r = results.pandas().xyxy[0].to_numpy()\n",
    "            for line in r:\n",
    "                isAlert = True\n",
    "                img1 = ImageDraw.Draw(result)  \n",
    "                img1.rectangle((line[0], line[1], line[2], line[3]), outline =\"red\")\n",
    "                array_groundpoints.append(((line[0] + line[3])/2, (line[1] + line[2])/2))\n",
    "                    \n",
    "            # –ø–æ–ª—É—á–∞–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–π –≤–∏–¥ —Å –≤—ã—Å–æ—Ç—ã –ø—Ç–∏—á—å–µ–≥–æ –ø–æ–ª–µ—Ç–∞\n",
    "            # —Å –ø–æ–º–æ—â—å—é cv2.getPerspectiveTranform()\n",
    "            horizonline = 140\n",
    "            calculatedangle = 75\n",
    "            height, width = im.shape[:2]\n",
    "            pts = np.array([\n",
    "                [calculatedangle, horizonline],\n",
    "                [width - calculatedangle, horizonline],\n",
    "                [0, height],\n",
    "                [width, height]], dtype = \"float32\")\n",
    "\n",
    "            warped, matrix = four_point_transform(im, pts)\n",
    "            transformed_downoids = compute_point_perspective_transformation(matrix, array_groundpoints)\n",
    "\n",
    "            if len(transformed_downoids) >= 1:\n",
    "                halfW = width / 2\n",
    "                dist = np.sqrt((float(transformed_downoids[0][0]) - halfW) ** 2 + (height - float(transformed_downoids[0][1])) ** 2)\n",
    "                dists.append(dist)\n",
    "                fire_area = get_fire_area(dist, width, get_avg(r))\n",
    "                filename = str(frame_count)\n",
    "                #print(\"distance: \", dist)\n",
    "                #print(\"whole_fire_area: \", fire_area, \"–≥–∞\")\n",
    "\n",
    "                for i in range(len(r)):\n",
    "                    fire_radius = get_fire_radius(dist, width, r[i][2] - r[i][0])\n",
    "                    fire_areas.append((i, fire_radius))\n",
    "                    #print(i, \" \", \"x:\", transformed_downoids[i][0], \"y:\", transformed_downoids[i][1], \" | damage_radius: \", fire_radius)\n",
    "\n",
    "                data_to_json = {\n",
    "                        \"frame\" : filename,\n",
    "                        \"isAlert\": str(isAlert),\n",
    "                        \"dist\": str(dist),\n",
    "                        \"area:\": str(fire_area)\n",
    "                }\n",
    "                \n",
    "                with open(\"data_file.json\", \"w+\") as write_file:\n",
    "                     json.dump(data_to_json, write_file)\n",
    "                array_groundpoints.clear()\n",
    "                \n",
    "            font = ImageFont.truetype('arial.ttf', 24) \n",
    "            img1.text((5, 5), \"–ù–∞–π–¥–µ–Ω–æ –≤–æ–∑–≥–æ—Ä–∞–Ω–∏–π: \" + str(len(transformed_downoids)), font = font, align =\"left\", fill=(255,0,0,255))\n",
    "            transformed_downoids.clear()\n",
    "            if len(dists) > 0:\n",
    "                img1.text((5, 35), \"–î–∏—Å—Ç–∞–Ω—Ü–∏—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ –æ—á–∞–≥–∞ (–≤ —É.–µ): \" + '{0:.3f}'.format(dists[0]), font = font, align =\"left\", fill=(255,0,0,255))\n",
    "                img1.text((5, 65), \"–ü–ª–æ—â–∞–¥—å –≤–æ–∑–≥–æ—Ä–∞–Ω–∏—è –ø–µ—Ä–≤–æ–≥–æ –æ—á–∞–≥–∞ (–≤ —É.–µ): \" + '{0:.3f}'.format(fire_areas[0][1]), font = font, align =\"left\", fill=(255,0,0,255))\n",
    "            dists.clear()\n",
    "            fire_areas.clear()\n",
    "                \n",
    "        out.write(cv2.cvtColor(np.array(result), cv2.COLOR_RGB2BGR))\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ad8f9-a3a8-4cab-9a71-3cc16288fda8",
   "metadata": {
    "id": "069ad8f9-a3a8-4cab-9a71-3cc16288fda8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "–ö–æ–ø–∏—è –±–ª–æ–∫–Ω–æ—Ç–∞ \"model-testing.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
